# Project Structure

```
KEREM-ALCI-DSA-210-PROJECT/
â”‚
â”œâ”€â”€ README.md                          # Main project documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies for the project
â”œâ”€â”€ test_results.py                    # Test/utility script
â”‚
â”œâ”€â”€ analysis/                          # ğŸ“Š Analysis scripts and results
â”‚   â”œâ”€â”€ README.md                      # Analysis folder documentation
â”‚   â”œâ”€â”€ analyze_data.py                # Main analysis script
â”‚   â””â”€â”€ ANALYSIS_SUMMARY.md            # Comprehensive findings and insights
â”‚
â”œâ”€â”€ data/                              # ğŸ’¾ All data files
â”‚   â”œâ”€â”€ README.md                      # Data folder documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ raw/                           # Raw scraped data (unprocessed)
â”‚   â”‚   â”œâ”€â”€ sahibinden/
â”‚   â”‚   â”‚   â”œâ”€â”€ sahibinden_enriched_listings.xlsx
â”‚   â”‚   â”‚   â”œâ”€â”€ sahibinden_local_listings.xlsx
â”‚   â”‚   â”‚   â””â”€â”€ sahibinden_local_listings_backup.xlsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ emlakjet/
â”‚   â”‚   â”‚   â”œâ”€â”€ emlakjet_listings.xlsx
â”‚   â”‚   â”‚   â””â”€â”€ emlakjet_listings_with_coordinates.xlsx
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ hepsiemlak/
â”‚   â”‚       â””â”€â”€ hepsiemlak_listings.xlsx
â”‚   â”‚
â”‚   â””â”€â”€ processed/                     # Cleaned and merged data
â”‚       â””â”€â”€ combined_rental_data.xlsx  # Final dataset for analysis
â”‚
â”œâ”€â”€ scrapers/                          # ğŸ•·ï¸ Web scraping scripts
â”‚   â”œâ”€â”€ README.md                      # Scrapers folder documentation
â”‚   â”‚
â”‚   â”œâ”€â”€ sahibinden/                    # Sahibinden.com scrapers
â”‚   â”‚   â”œâ”€â”€ requirements.txt           # Specific dependencies
â”‚   â”‚   â”œâ”€â”€ run_scraper.bat           # Batch script for Windows
â”‚   â”‚   â”œâ”€â”€ scraper_sahibinden.py     # Main scraper
â”‚   â”‚   â””â”€â”€ scraper_sahibinden_uc.py  # Undetected Chrome version
â”‚   â”‚
â”‚   â”œâ”€â”€ emlakjet/                      # Emlakjet.com scraper
â”‚   â”‚   â””â”€â”€ scraper_emlakjet.py
â”‚   â”‚
â”‚   â””â”€â”€ hepsiemlak/                    # Hepsiemlak.com scraper
â”‚       â””â”€â”€ scraper_hepsiemlak.py
â”‚
â””â”€â”€ visualizations/                    # ğŸ“ˆ Generated charts and plots
    â”œâ”€â”€ README.md                      # Visualizations folder documentation
    â”œâ”€â”€ analysis_overview.png          # Main analysis visualizations
    â”œâ”€â”€ distance_analysis.png          # Distance-related plots
    â”œâ”€â”€ analysis_results.png           # Summary results
    â””â”€â”€ merged_analysis_plots.png      # Combined plots

```

## Folder Purposes

### ğŸ“Š analysis/
Contains all analysis-related code and documentation. Run `python analyze_data.py` from this folder to perform the complete analysis.

### ğŸ’¾ data/
- **raw/**: Original scraped data from each website, organized by source
- **processed/**: Cleaned, standardized, and merged datasets ready for analysis

### ğŸ•·ï¸ scrapers/
Web scraping scripts organized by source website. Each subfolder contains the scraper(s) for that specific platform.

### ğŸ“ˆ visualizations/
All generated charts and plots from the analysis. Automatically created/updated when running the analysis script.

## Workflow

1. **Collect Data**: Run scrapers from `scrapers/*/` folders â†’ saves to `data/raw/*/`
2. **Analyze**: Run `python analyze_data.py` from `analysis/` folder
3. **Results**: 
   - Visualizations â†’ saved to `visualizations/`
   - Processed data â†’ saved to `data/processed/`
   - Findings â†’ documented in `analysis/ANALYSIS_SUMMARY.md`

## Notes

- Each major folder contains its own README.md with specific documentation
- All paths in scripts use relative references for portability
- Virtual environment (`.venv/`) and git files (`.git/`) are excluded from version control of data
