# Emlakjet Data Collection - Action Plan

## Current Status
- âŒ Old data (19 listings) has expired URLs
- âœ… 3 scrapers created and ready
- âœ… All dependencies installed
- ğŸ¯ **Goal**: Collect 30-50 fresh KurtkÃ¶y rental listings

## ğŸš€ Recommended Workflow

### Option A: Semi-Automated (Easiest - 10 minutes)

**Step 1: Collect URLs with Helper Script**
```bash
cd scrapers/emlakjet
python collect_urls.py
```

What happens:
1. Browser opens automatically
2. You search for "KurtkÃ¶y Pendik kiralÄ±k daire" in the browser
3. Press Enter in terminal
4. Script extracts all URLs â†’ saves to `emlakjet_urls.txt`

**Step 2: Scrape Listings**
```bash
python scraper_emlakjet_selenium.py
# When prompted, enter: emlakjet_urls.txt
```

**Step 3: Check Results**
- New file created: `../../data/raw/emlakjet/emlakjet_listings_TIMESTAMP.xlsx`
- Contains all listing details + distances

---

### Option B: Fully Manual (More Control - 15 minutes)

**Step 1: Collect URLs Manually**
1. Open https://www.emlakjet.com in your browser
2. Search: "KurtkÃ¶y Pendik kiralÄ±k daire"
3. For each listing:
   - Right-click â†’ Copy link address
   - Paste into a text file (`emlakjet_urls.txt`)
4. Save file (one URL per line)

**Step 2: Scrape Listings**
```bash
cd scrapers/emlakjet
python scraper_emlakjet_selenium.py
# Provide path to your emlakjet_urls.txt
```

---

### Option C: Browser Console (Advanced - 5 minutes)

**Step 1: Use JavaScript Console**
1. Open Emlakjet search results in browser
2. Open DevTools (F12) â†’ Console tab
3. Paste and run:
```javascript
let urls = [];
document.querySelectorAll('a[href*="/ilan/"]').forEach(a => {
    if (a.href && a.href.includes('/ilan/') && !urls.includes(a.href)) {
        urls.push(a.href);
    }
});
console.log(urls.join('\\n'));
```
4. Copy output â†’ Save to `emlakjet_urls.txt`

**Step 2: Run Scraper**
```bash
python scraper_emlakjet_selenium.py
```

---

## ğŸ“‹ What You'll Get

For each listing:
- âœ… Price (â‚º/month)
- âœ… Area (mÂ²)
- âœ… Room count (2+1, 3+1, etc.)
- âœ… Building age
- âœ… Floor number
- âœ… Number of bathrooms
- âœ… Furnishment status
- âœ… Coordinates (latitude, longitude)
- âœ… Distance to KurtkÃ¶y Metro
- âœ… Distance to SabancÄ± University
- âœ… Distance to Bus Station

## ğŸ¯ Success Metrics

**Target**: 30-50 fresh listings
- Minimum for good analysis: 20 listings
- Optimal for statistics: 40-50 listings
- Combined with Sahibinden & Hepsiemlak: 80-100 total

## âš ï¸ Important Notes

1. **URL Quality**: Make sure URLs are actual listings (contain `/ilan/` and a listing ID)
2. **Active Listings**: Check that listings show prices (not "removed" or "sold")
3. **Location**: Verify listings are actually in KurtkÃ¶y area
4. **Delays**: Scraper has built-in 4-8 second delays between requests to be respectful

## ğŸ”§ Troubleshooting

**Browser doesn't open?**
- Check Chrome is installed
- Try: `pip install --upgrade undetected-chromedriver`

**No URLs extracted?**
- Emlakjet may have changed their HTML structure
- Use manual method (Option B)
- Check browser console for JavaScript errors

**Scraper crashes mid-way?**
- Data is saved progressively (mostly)
- Check the output file for partial data
- Resume with remaining URLs

## ğŸ“Š After Collection

Once you have the new data:

```bash
# Go to analysis folder
cd ../../analysis

# Run analysis with new data
python analyze_data.py
```

The analysis script will automatically include the new Emlakjet data!

---

## âœ… Ready to Start?

**Recommended for you**: Use **Option A** (Semi-Automated)

Run this command:
```bash
cd /Users/mchalil/Documents/keremalc/KEREM-ALCI-DSA-210-PROJECT/scrapers/emlakjet
python collect_urls.py
```

Then follow the on-screen instructions! ğŸš€
